# Configuration file for Adaptive UI System

# Camera settings
camera:
  index: 0
  width: 640
  height: 480
  fps: 30

# Gaze tracking settings
gaze_tracking:
  # Select gaze tracker backend:
  # - direct: DirectGazeTracker (2D iris-based; supports 9-point calibration)
  # - monitor_plane: MonitorPlaneGazeTracker (ported monitor tracking; supports center calibration)
  mode: direct
  use_kalman: true
  kalman_process_noise: 0.01
  kalman_measurement_noise: 0.1
  fixation_radius: 0.05  # 5% of screen size
  # Settings for mode: monitor_plane
  monitor_plane:
    yaw_degrees: 15.0
    pitch_degrees: 5.0
    direction_filter_length: 15
    screen_smoothing_length: 8
    monitor_width: 1920
    monitor_height: 1080
    auto_lock_eye_spheres: true
    auto_lock_frames_required: 20

# Emotion detection settings
emotion_detection:
  model_path: null  # Set path to TensorFlow Lite model
  input_size: [48, 48]
  negative_emotions: ['angry', 'sad', 'fear', 'disgust']
  # ViT model settings
  temperature_scaling: 0.7  # Lower = more confident predictions (0.6-1.0)
  enable_neutral_bias_reduction: true
  neutral_bias_threshold: 0.35  # Reduce neutral if above this
  neutral_bias_reduction_amount: 0.15  # How much to reduce

# Cognitive load monitoring thresholds
cognitive_load:
  gaze_wander_threshold: 0.3
  fixation_duration_threshold: 3.0  # seconds
  negative_affect_threshold: 0.5
  gaze_history_window: 30
  overload_threshold: 0.6

  # Windowing / update behavior:
  # - window_duration_sec > 0: compute metrics over the last N seconds
  # - window_duration_sec <= 0: compute metrics over ALL collected samples (keeps every data point)
  # - update_interval_sec > 0: compute CLI every N seconds
  # - update_interval_sec <= 0: compute CLI on EVERY call (per data point / per frame)
  window_duration_sec: 10.0
  update_interval_sec: 0.0
  
  # CLI Weights (for research: use equal weights to avoid bias)
  # Set weights based on research question:
  # - Equal weights (0.33, 0.33, 0.33): No bias, let data reveal importance
  # - Individual analysis: Set one weight to 1.0, others to 0.0 for separate testing
  # - After discovery: Set weights based on data-driven findings
  weight_gaze: 0.333      # Equal weight (1/3) - unbiased for research
  weight_emotion: 0.333   # Equal weight (1/3) - unbiased for research  
  weight_mouse: 0.334     # Equal weight (1/3) - unbiased for research
  # NOTE: Weights should sum to 1.0

# UI adaptation settings
adaptation:
  enable_simplification: true
  enable_guidance: true
  enable_layout_reorganization: false
  font_size_multiplier: 1.2
  whitespace_multiplier: 1.5

# Metrics collection
metrics:
  enable_nasatlx: true
  enable_pupil_dilation: false  # Requires additional hardware
  export_format: 'json'
  export_directory: 'results'

# Data storage
data:
  store_raw_video: false  # Privacy: no raw video storage
  store_processed_data: true
  data_directory: 'data/processed'

# Logging
logging:
  level: 'INFO'
  log_directory: 'logs'
  log_file: 'adaptive_ui.log'

